{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import KFold \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Please implement a simple linear regression model using the closed-form solution (normal equation) and\n",
    "stochastic gradient descent to train the model on this dataset for predicting the house price (in millions).\n",
    "Split the data into training, validation, and test. Report the mean squared error (MSE) on the test data.\n",
    "Draw the training and validation loss curves. You need to write down every step in your experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Approch***\n",
    "\n",
    "Our linear model is $$y(w,X) = w_0 + w_1X_1 + .. + w_mX_m$$\n",
    "\n",
    "For this problem we employ two approaches to fit this model as suggested in the problem statement\n",
    "1. We fit the model using a closed form solution (normal equation) of the form $$w=(X^TX)^{-1}X^Ty$$, where $w$ represents the weight vector (coefficients in the linear model), $X$ is the the feature matrix (input data) and $y$ is the label vector (target variables that we are trying to predict).\n",
    "2. In the second approach we fit the linear model by trying to minimize the cost function via gradient descent. We utilize stochastic gradient descent. Our cost function is the mean squared error of the form $$\\frac{1}{m}\\sum_{i=1}^{m}(y(w,x^{(i)}) - y^{(i)})^2$$ where $m$ is the number of samples.\n",
    "Our stochastic gradient is obtained by calculating the 1st derivative of the cost function for a randomly chosen sample and is of the form $$\\nabla^{(i)} = 2x^{(i)T}(x^{(i)}w - y^{(i)})$$ where $x^{(i)}$ is the randomly chosen sample.\n",
    "Once we obtain the gradient, we update the weights using $$w = w - \\eta.\\nabla^{(i)}$$ where $\\eta$ is the learning rate.\n",
    "\n",
    "***Data preparation steps***\n",
    "1. Once we obtain the data, for our closed form approach we split it into a training and a test set. \n",
    "2. For the gradient descent approach, we split the data into a training, validation and test sets.\n",
    "3. Since linear regression can be sensitive to differing scales in data, we standardize the input columns by subtracting mean and dividing by standard deviation.\n",
    "3. We also stack a column of 1's to the input data to account for the bias term $w_0$\n",
    "\n",
    "***Model fitting and prediction***\n",
    "1. For approach 1, model fitting is simply solving the normal equation for the entire training set. We then predict the test labels using the test set and we calculate error using the mean squared error formula outlined above.\n",
    "2. For approach 2, we run multiple iterations(epochs) and in each iteration we process the entire training set. For each such processing step, we pick a random (stochastic) sample from the training set, calculate the gradient and update the weights as outlined above. \n",
    "3. For each iteration we also calculate the overall training MSE and validation MSE. Finally we plot the training and validation losses, make predictions on the test set and calculate the test MSE as well.\n",
    "4. We have chosen 500 iterations as the total number of epochs for this experiment, but improvements can be made by choosing a higher epoch count and adding a suitable stopping criterion when the validation loss stops decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "x = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "y = pd.DataFrame(housing.target, columns=['PRICE'])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20640 8\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "num_data = x.shape[0]\n",
    "num_features = x.shape[1]\n",
    "print(num_data,num_features)\n",
    "\n",
    "shuffled = np.random.permutation(num_data)\n",
    "\n",
    "# calculate num of test samples\n",
    "test_set = int(num_data * 0.2)\n",
    "\n",
    "# split indices into test and train\n",
    "test_indices = shuffled[:test_set]\n",
    "train_indices = shuffled[test_set:]\n",
    "\n",
    "# split the data\n",
    "x_train_pre = x.iloc[train_indices]\n",
    "x_test = x.iloc[test_indices]\n",
    "y_train = y.iloc[train_indices]\n",
    "y_test = y.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16512 8\n"
     ]
    }
   ],
   "source": [
    "# train valid split\n",
    "num_data = x_train_pre.shape[0]\n",
    "num_features = x_train_pre.shape[1]\n",
    "print(num_data,num_features)\n",
    "\n",
    "# shuffling data\n",
    "shuffled = np.random.permutation(num_data)\n",
    "\n",
    "# calculate num of test samples\n",
    "test_set = int(num_data * 0.2)\n",
    "\n",
    "# split indices into test and train\n",
    "test_indices = shuffled[:test_set]\n",
    "train_indices = shuffled[test_set:]\n",
    "\n",
    "# split the data\n",
    "x_train = x_train_pre.iloc[train_indices]\n",
    "x_valid = x_train_pre.iloc[test_indices]\n",
    "y_train = y.iloc[train_indices]\n",
    "y_valid = y.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute normal equation: w = (x^T x)^(-1) x^T y\n",
    "xtx = np.dot(x_train.T, x_train)  # X^T * X\n",
    "xtx_inv = np.linalg.inv(xtx)              # (X^T * X)^(-1)\n",
    "xty = np.dot(x_train.T, y_train)            # X^T * y\n",
    "\n",
    "# Compute the coefficients (theta)\n",
    "w = np.dot(xtx_inv, xty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.321230092203056\n"
     ]
    }
   ],
   "source": [
    "# calculating y prediction for test data\n",
    "y_pred_test = np.dot(x_test,w)\n",
    "\n",
    "# MSE\n",
    "mse = np.mean((y_pred_test - y_test) ** 2)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating standardization function\n",
    "def standardize(x_train):\n",
    "    #calculate mean & std of training set\n",
    "    mean = np.mean(x_train, axis = 0)\n",
    "    sd = np.std(x_train, axis = 0)\n",
    "\n",
    "    # to prevent division by 0, set std = 1 where it is 0\n",
    "    sd[sd==0] = 1\n",
    "\n",
    "    #standardize the training set\n",
    "    x_train_scaled = (x_train - mean) / sd\n",
    "\n",
    "    return x_train_scaled, mean, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing data \n",
    "x_train_scaled, mean, sd = standardize(x_train)\n",
    "x_test_scaled = (x_test - mean) / sd\n",
    "x_valid_scaled = (x_valid - mean) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column of ones to x for intercept term\n",
    "x_train_int_scaled = np.column_stack([np.ones(x_train_scaled.shape[0]), x_train_scaled])\n",
    "x_test_int_scaled = np.column_stack([np.ones(x_test_scaled.shape[0]), x_test_scaled])\n",
    "x_valid_int_scaled = np.column_stack([np.ones(x_valid_scaled.shape[0]), x_valid_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining sgd function \n",
    "def sgd(x,y,xval, yval, learning_rate = 0.00001, n_iter = 500):\n",
    "    # storing data shape, initializing parameter\n",
    "    m,n = x.shape\n",
    "    w = np.random.randn(n,1)\n",
    "    y = y.reshape(-1,1)\n",
    "    # creating empty lists for storage\n",
    "    mse_history = []\n",
    "    mse_valid_history = []\n",
    "\n",
    "    for iter in range(n_iter):\n",
    "        for i in range(m):\n",
    "            random_idx = np.random.randint(m)\n",
    "            xi = x[random_idx:random_idx+1]\n",
    "            yi = y[random_idx:random_idx+1]\n",
    "            # compute predicted gradient of loss function\n",
    "            gradients = 2*xi.T.dot(xi.dot(w)-yi)\n",
    "            # update parameter\n",
    "            w = w - learning_rate *gradients\n",
    "\n",
    "        # store train mse \n",
    "        mse = np.mean((x.dot(w) - y) ** 2,axis=0)[0]\n",
    "        mse_history.append(mse)\n",
    "\n",
    "        # store valid mse \n",
    "        mse_valid = np.mean((xval.dot(w) - yval) ** 2, axis=0)[0]\n",
    "        mse_valid_history.append(mse_valid)\n",
    "\n",
    "        if iter % 10 == 0 and iter != 0:\n",
    "            print(f\"Iteration {iter}: MSE = {mse_history[-1]}, {mse_valid_history[-1]} \")\n",
    "            \n",
    "    return w, mse_history, mse_valid_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10: MSE = 1.3306113199338534, 1.3530387581764127 \n",
      "Iteration 20: MSE = 1.310506837026128, 1.3366301438626111 \n",
      "Iteration 30: MSE = 1.301384212146088, 1.3298494613717737 \n",
      "Iteration 40: MSE = 1.2947952979956703, 1.324745196624922 \n",
      "Iteration 50: MSE = 1.290503949886495, 1.3211598636354906 \n",
      "Iteration 60: MSE = 1.2878262760183585, 1.319181847685343 \n",
      "Iteration 70: MSE = 1.285913521209873, 1.3174038554638159 \n",
      "Iteration 80: MSE = 1.2845750238429, 1.3165857805888492 \n",
      "Iteration 90: MSE = 1.2836793337288692, 1.316304765276699 \n",
      "Iteration 100: MSE = 1.2830405140210608, 1.315975534783687 \n",
      "Iteration 110: MSE = 1.282673233666663, 1.315874258971893 \n",
      "Iteration 120: MSE = 1.2826308721000967, 1.3155707521690505 \n",
      "Iteration 130: MSE = 1.2821677857440892, 1.314889087093523 \n",
      "Iteration 140: MSE = 1.2820579108483332, 1.3155538844787333 \n",
      "Iteration 150: MSE = 1.2820306260473389, 1.314709653770706 \n",
      "Iteration 160: MSE = 1.2819582973633286, 1.3152422281337262 \n",
      "Iteration 170: MSE = 1.281849240904822, 1.3148024449191051 \n",
      "Iteration 180: MSE = 1.281832869983546, 1.3153865356815926 \n",
      "Iteration 190: MSE = 1.2818056825012794, 1.315048674671528 \n",
      "Iteration 200: MSE = 1.2819410882353166, 1.3156387491969705 \n",
      "Iteration 210: MSE = 1.2818456796721642, 1.3146592321308124 \n",
      "Iteration 220: MSE = 1.2818999890547003, 1.314968532225437 \n",
      "Iteration 230: MSE = 1.2817452840577026, 1.314969213747074 \n",
      "Iteration 240: MSE = 1.2818421503988122, 1.3151298443736559 \n",
      "Iteration 250: MSE = 1.2818655496282756, 1.3149476114748648 \n",
      "Iteration 260: MSE = 1.2819348202682082, 1.3150923969006296 \n",
      "Iteration 270: MSE = 1.2817635527608267, 1.314606949104349 \n",
      "Iteration 280: MSE = 1.2818213869480966, 1.3149837847006938 \n",
      "Iteration 290: MSE = 1.281759106111541, 1.314613634110722 \n",
      "Iteration 300: MSE = 1.2818260262529433, 1.3150193654059388 \n",
      "Iteration 310: MSE = 1.2818715625462704, 1.3156195603560297 \n",
      "Iteration 320: MSE = 1.281933491562572, 1.3156343720742316 \n",
      "Iteration 330: MSE = 1.2818524146877606, 1.3145316682537875 \n",
      "Iteration 340: MSE = 1.2818715939005614, 1.3150917074402504 \n",
      "Iteration 350: MSE = 1.2819144011144197, 1.315350282451973 \n",
      "Iteration 360: MSE = 1.2818807264371637, 1.314838858799275 \n",
      "Iteration 370: MSE = 1.281758423585892, 1.3147514876153665 \n",
      "Iteration 380: MSE = 1.2817812346735424, 1.3152242185403527 \n",
      "Iteration 390: MSE = 1.2817845222984925, 1.3147807581120643 \n",
      "Iteration 400: MSE = 1.2817457836758868, 1.314877445350511 \n",
      "Iteration 410: MSE = 1.2818812591357909, 1.3150431325226735 \n",
      "Iteration 420: MSE = 1.2817855098035311, 1.3151856329528249 \n",
      "Iteration 430: MSE = 1.281789724306122, 1.31513937257588 \n",
      "Iteration 440: MSE = 1.2818115443056846, 1.3147353699163042 \n",
      "Iteration 450: MSE = 1.281748183390867, 1.3147832226521778 \n",
      "Iteration 460: MSE = 1.2817454974015328, 1.314592978134108 \n",
      "Iteration 470: MSE = 1.2818874071326767, 1.3147718414928926 \n",
      "Iteration 480: MSE = 1.2817594188973027, 1.3149469124127267 \n",
      "Iteration 490: MSE = 1.2817526699962978, 1.3144626485030986 \n"
     ]
    }
   ],
   "source": [
    "# Train the model using SGD\n",
    "theta_sgd, mse_history, mse_valid_history = sgd(x_train_int_scaled, y_train.values, x_valid_int_scaled, y_valid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_sgd = np.dot(x_test_int_scaled, theta_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Mean Squared Error: 1.3475819549901296\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "# Mean Squared Error (MSE)\n",
    "mse_sgd = np.mean((y_pred_sgd - y_test.values) ** 2)\n",
    "print(f\"SGD Mean Squared Error: {mse_sgd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot mse test and mse valid\n",
    "ax = sns.lineplot(x = range(0,500), y = mse_history)\n",
    "sns.lineplot(x = range(0,500), y = mse_valid_history, ax = ax)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Please write a Ridge regression model and use mini-batch gradient descent to train the model on this dataset for predicting the count of total rental bikes including both casual and registered. You do not need to use all the features. Use K-fold cross validation and report the mean squared error (MSE) on the test data. You need to write down every step in your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Approch***\n",
    "\n",
    "Our model is $$y(w,X) = w_0 + w_1X_1 + .. + w_mX_m$$\n",
    "\n",
    "For this problem we fit the linear model by trying to minimize the cost function via gradient descent. We utilize mini batch gradient descent. Our cost function is the mean squared error of the form $$\\frac{1}{m}[\\sum_{i=1}^{m}(y(w,X) - y)^2+\\alpha\\sum_{k=1}^{n}w_k^2]$$ where $X$ is the randomly chosen mini batch of size $m$.\n",
    "Our mini batch gradient is obtained by calculating the 1st derivative of the cost function and is of the form $$\\nabla = \\frac{2}{m}[{X^T}(Xw - y) + \\alpha w]$$ .\n",
    "Once we obtain the gradient, we update the weights using $$w = w - \\eta.\\nabla$$ where $\\eta$ is the learning rate.\n",
    "\n",
    "***Data preparation steps***\n",
    "1. Once we obtain the data, we split the data into a training and test sets.\n",
    "3. Since linear regression can be sensitive to differing scales in data, we standardize the input columns by subtracting mean and dividing by standard deviation.\n",
    "3. We also stack a column of 1's to the input data to account for the bias term $w_0$\n",
    "\n",
    "***Model fitting and prediction***\n",
    "1. We run multiple iterations(epochs) and in each iteration we use kfold cross validation with 7 folds. \n",
    "2. For each step in the kfold cross validation, 6 fold are taken as the training set and the last fold is used as validation. For each of these iterations, we process the entire training set. For each such processing step, we take a batch of samples from the training set, calculate the gradient and update the weights as outlined above for each batch. \n",
    "2. For each fold iteration we also calculate the overall training MSE and validation MSE. For each epoch we average the fold level errors. Finally we plot these training and validation losses, make predictions on the test set and calculate the test MSE as well.\n",
    "3. We have chosen 2000 iterations as the total number of epochs for this experiment, but improvements can be made by choosing a higher epoch count and adding a suitable stopping criterion when the validation loss stops decreasing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 275, 'name': 'Bike Sharing', 'repository_url': 'https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/275/data.csv', 'abstract': 'This dataset contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information.', 'area': 'Social Science', 'tasks': ['Regression'], 'characteristics': ['Multivariate'], 'num_instances': 17389, 'num_features': 13, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['cnt'], 'index_col': ['instant'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2013, 'last_updated': 'Sun Mar 10 2024', 'dataset_doi': '10.24432/C5W894', 'creators': ['Hadi Fanaee-T'], 'intro_paper': {'title': 'Event labeling combining ensemble detectors and background knowledge', 'authors': 'Hadi Fanaee-T, João Gama', 'published_in': 'Progress in Artificial Intelligence', 'year': 2013, 'url': 'https://www.semanticscholar.org/paper/bc42899f599d31a5d759f3e0a3ea8b52479d6423', 'doi': '10.1007/s13748-013-0040-3'}, 'additional_info': {'summary': 'Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. \\r\\n\\r\\nApart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Both hour.csv and day.csv have the following fields, except hr which is not available in day.csv\\r\\n\\t\\r\\n\\t- instant: record index\\r\\n\\t- dteday : date\\r\\n\\t- season : season (1:winter, 2:spring, 3:summer, 4:fall)\\r\\n\\t- yr : year (0: 2011, 1:2012)\\r\\n\\t- mnth : month ( 1 to 12)\\r\\n\\t- hr : hour (0 to 23)\\r\\n\\t- holiday : weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\\r\\n\\t- weekday : day of the week\\r\\n\\t- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\\r\\n\\t+ weathersit : \\r\\n\\t\\t- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\\r\\n\\t\\t- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\\r\\n\\t\\t- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\\r\\n\\t\\t- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\\r\\n\\t- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\\r\\n\\t- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\\r\\n\\t- hum: Normalized humidity. The values are divided to 100 (max)\\r\\n\\t- windspeed: Normalized wind speed. The values are divided to 67 (max)\\r\\n\\t- casual: count of casual users\\r\\n\\t- registered: count of registered users\\r\\n\\t- cnt: count of total rental bikes including both casual and registered\\r\\n', 'citation': None}}\n",
      "          name     role         type demographic  \\\n",
      "0      instant       ID      Integer        None   \n",
      "1       dteday  Feature         Date        None   \n",
      "2       season  Feature  Categorical        None   \n",
      "3           yr  Feature  Categorical        None   \n",
      "4         mnth  Feature  Categorical        None   \n",
      "5           hr  Feature  Categorical        None   \n",
      "6      holiday  Feature       Binary        None   \n",
      "7      weekday  Feature  Categorical        None   \n",
      "8   workingday  Feature       Binary        None   \n",
      "9   weathersit  Feature  Categorical        None   \n",
      "10        temp  Feature   Continuous        None   \n",
      "11       atemp  Feature   Continuous        None   \n",
      "12         hum  Feature   Continuous        None   \n",
      "13   windspeed  Feature   Continuous        None   \n",
      "14      casual    Other      Integer        None   \n",
      "15  registered    Other      Integer        None   \n",
      "16         cnt   Target      Integer        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                        record index  None             no  \n",
      "1                                                date  None             no  \n",
      "2                1:winter, 2:spring, 3:summer, 4:fall  None             no  \n",
      "3                             year (0: 2011, 1: 2012)  None             no  \n",
      "4                                     month (1 to 12)  None             no  \n",
      "5                                      hour (0 to 23)  None             no  \n",
      "6   weather day is holiday or not (extracted from ...  None             no  \n",
      "7                                     day of the week  None             no  \n",
      "8   if day is neither weekend nor holiday is 1, ot...  None             no  \n",
      "9   - 1: Clear, Few clouds, Partly cloudy, Partly ...  None             no  \n",
      "10  Normalized temperature in Celsius. The values ...     C             no  \n",
      "11  Normalized feeling temperature in Celsius. The...     C             no  \n",
      "12  Normalized humidity. The values are divided to...  None             no  \n",
      "13  Normalized wind speed. The values are divided ...  None             no  \n",
      "14                              count of casual users  None             no  \n",
      "15                          count of registered users  None             no  \n",
      "16  count of total rental bikes including both cas...  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "bike_sharing = fetch_ucirepo(id=275) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "x = bike_sharing.data.features \n",
    "y = bike_sharing.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(bike_sharing.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(bike_sharing.variables) \n",
    "\n",
    "# dropping date column and one hot encoding categoricals (season, yr, mnth, hr, weekday, weathersit)\n",
    "x = x.drop(['dteday', 'yr'], axis = 1)\n",
    "x = pd.get_dummies(data = x, columns = ['season', 'mnth', 'hr', 'weekday', 'weathersit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17379 57\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "num_data = x.shape[0]\n",
    "num_features = x.shape[1]\n",
    "print(num_data,num_features)\n",
    "\n",
    "# shuffling data\n",
    "shuffled = np.random.permutation(num_data)\n",
    "\n",
    "# calculate num of test samples\n",
    "test_set = int(num_data * 0.2)\n",
    "\n",
    "# split indices into test and train\n",
    "test_indices = shuffled[:test_set]\n",
    "train_indices = shuffled[test_set:]\n",
    "\n",
    "# split the data\n",
    "x_train = x.iloc[train_indices]\n",
    "x_test = x.iloc[test_indices]\n",
    "y_train = y.iloc[train_indices]\n",
    "y_test = y.iloc[test_indices]\n",
    "\n",
    "#standardize \n",
    "x_train_scaled, mean, sd = standardize(x_train) \n",
    "x_test_scaled = (x_test - mean) / sd\n",
    "\n",
    "# add column of ones to x for intercept term\n",
    "x_train_int = np.column_stack([np.ones(x_train_scaled.shape[0]), x_train_scaled])\n",
    "x_test_int = np.column_stack([np.ones(x_test_scaled.shape[0]), x_test_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining ridge function\n",
    "def ridge(x,y,learning_rate = 0.0001, n_iter = 2000):\n",
    "    # initializing parameter\n",
    "    m,n = x.shape\n",
    "    w = np.random.randn(n,1)\n",
    "    y = y.reshape(-1,1)\n",
    "    # Set some batch_size variable to mini batch size you want per iteration\n",
    "    batch_size = 700 \n",
    "    alpha = 0.0001\n",
    "    # create some lists for overall training loss and validation loss\n",
    "    training_loss = []\n",
    "    valid_loss = []    \n",
    "\n",
    "    for iter in range(n_iter):\n",
    "        # create some lists to hold the losses for each fold loop\n",
    "        fold_training_loss = []\n",
    "        fold_val_loss = []\n",
    "        # Create the KFold()\n",
    "        kf = KFold(n_splits=7, shuffle = True, random_state = 777)\n",
    "\n",
    "        for (training_index, validation_index) in kf.split(x):\n",
    "            # Use the train index to get the training folds from the train_X and train_y data\n",
    "            train_x_fold = x[training_index]\n",
    "            train_y_fold = y[training_index]\n",
    "            \n",
    "            # Use the validation indices to get the validation data from the same train_X and train_y data\n",
    "            valid_x_fold = x[validation_index]\n",
    "            valid_y_fold = y[validation_index]\n",
    "\n",
    "            # calculate batch_count\n",
    "            batch_count = train_x_fold.shape[0]//batch_size + (0 if train_x_fold.shape[0]%batch_size == 0 else 1)\n",
    "\n",
    "            for idx in range(batch_count):\n",
    "                 # Get the batch X data from the train X data fold\n",
    "                batch_x = train_x_fold[idx*batch_size: (idx + 1)*batch_size]\n",
    "\n",
    "                # Get the batch Y data from the train Y data fold\n",
    "                batch_y = train_y_fold[idx*batch_size: (idx + 1)*batch_size]\n",
    "\n",
    "                # calculate your ridge gradient using the ridge forumula\n",
    "                ridge_gradients = (2*batch_x.T.dot(batch_x.dot(w)-batch_y) + 2*np.dot(alpha,w))/batch_x.shape[0]\n",
    "\n",
    "                # update theta\n",
    "                w = w - learning_rate * ridge_gradients\n",
    "\n",
    "            # calculate training loss and validation loss MSE for this batch and store it in the lists for fold level losses\n",
    "            train_mse = np.mean((train_x_fold.dot(w) - train_y_fold) ** 2)\n",
    "            fold_training_loss.append(train_mse)\n",
    "            \n",
    "            valid_mse = np.mean((valid_x_fold.dot(w) - valid_y_fold) ** 2)\n",
    "            fold_val_loss.append(valid_mse)\n",
    "    \n",
    "        #calculate the training loss and validation loss for this iteration by averageing the training loss and validation loss from the folds level lists\n",
    "        training_loss.append(np.average(fold_training_loss))\n",
    "        valid_loss.append(np.average(fold_val_loss))  \n",
    "         \n",
    "        if iter%50 == 0: \n",
    "            print(f'epoch number: {iter}, t loss: {training_loss[-1]}, v loss: {valid_loss[-1]}' )\n",
    "    return (w, training_loss, valid_loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0, t loss: 65720.83534913449, v loss: 65735.91173235992\n",
      "epoch number: 50, t loss: 15861.193140932979, v loss: 15862.575650485176\n",
      "epoch number: 100, t loss: 12363.454139273983, v loss: 12363.721119091713\n",
      "epoch number: 150, t loss: 12046.63521987545, v loss: 12046.806360729408\n",
      "epoch number: 200, t loss: 12009.115901498253, v loss: 12009.282130026762\n",
      "epoch number: 250, t loss: 12000.845562867455, v loss: 12001.013732057092\n",
      "epoch number: 300, t loss: 11997.299220674262, v loss: 11997.468586794837\n",
      "epoch number: 350, t loss: 11995.23929547463, v loss: 11995.409053738273\n",
      "epoch number: 400, t loss: 11993.903134451613, v loss: 11994.072873807207\n",
      "epoch number: 450, t loss: 11992.9840221404, v loss: 11993.153566845474\n",
      "epoch number: 500, t loss: 11992.323606359178, v loss: 11992.492895105102\n",
      "epoch number: 550, t loss: 11991.831286178853, v loss: 11992.00030998341\n",
      "epoch number: 600, t loss: 11991.452164098597, v loss: 11991.620936674886\n",
      "epoch number: 650, t loss: 11991.15158143755, v loss: 11991.320125251386\n",
      "epoch number: 700, t loss: 11990.906934619057, v loss: 11991.075274362302\n",
      "epoch number: 750, t loss: 11990.703079230605, v loss: 11990.871238834357\n",
      "epoch number: 800, t loss: 11990.52962871239, v loss: 11990.69763007738\n",
      "epoch number: 850, t loss: 11990.379308209884, v loss: 11990.547170777581\n",
      "epoch number: 900, t loss: 11990.24692219238, v loss: 11990.414662923633\n",
      "epoch number: 950, t loss: 11990.128691778134, v loss: 11990.296325320145\n",
      "epoch number: 1000, t loss: 11990.021820959213, v loss: 11990.189359888484\n",
      "epoch number: 1050, t loss: 11989.924207656632, v loss: 11990.091662740382\n",
      "epoch number: 1100, t loss: 11989.834248055875, v loss: 11990.00162850362\n",
      "epoch number: 1150, t loss: 11989.75070195702, v loss: 11989.91801564943\n",
      "epoch number: 1200, t loss: 11989.672598612477, v loss: 11989.839852302899\n",
      "epoch number: 1250, t loss: 11989.59916981399, v loss: 11989.766369302402\n",
      "epoch number: 1300, t loss: 11989.529801585266, v loss: 11989.696951866465\n",
      "epoch number: 1350, t loss: 11989.463998768455, v loss: 11989.631104157294\n",
      "epoch number: 1400, t loss: 11989.401358683719, v loss: 11989.56842292036\n",
      "epoch number: 1450, t loss: 11989.341551272624, v loss: 11989.50857761071\n",
      "epoch number: 1500, t loss: 11989.284303946586, v loss: 11989.451295227016\n",
      "epoch number: 1550, t loss: 11989.229389900493, v loss: 11989.396348613129\n",
      "epoch number: 1600, t loss: 11989.176619014286, v loss: 11989.34354734956\n",
      "epoch number: 1650, t loss: 11989.12583071234, v loss: 11989.292730604515\n",
      "epoch number: 1700, t loss: 11989.076888321068, v loss: 11989.243761484542\n",
      "epoch number: 1750, t loss: 11989.029674584823, v loss: 11989.196522544682\n",
      "epoch number: 1800, t loss: 11988.98408808518, v loss: 11989.150912202951\n",
      "epoch number: 1850, t loss: 11988.940040370002, v loss: 11989.10684186546\n",
      "epoch number: 1900, t loss: 11988.897453643827, v loss: 11989.064233613479\n",
      "epoch number: 1950, t loss: 11988.856258904354, v loss: 11989.023018337191\n"
     ]
    }
   ],
   "source": [
    "# Train the model using ridge \n",
    "theta_ridge, train_loss, val_loss = ridge(x_train_int, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training loss vs validation loss \n",
    "ax = sns.lineplot(x = range(0,2000), y = train_loss)\n",
    "sns.lineplot(x = range(0,2000), y = val_loss, ax = ax)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
